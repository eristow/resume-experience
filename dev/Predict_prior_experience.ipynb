{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwHKEOoSK-W7",
        "outputId": "49989fab-92fa-47be-df84-58f1737575d4"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.retrievers import BM25Retriever\n",
        "from tools import CustomEmbeddings, process_file, extract_text_from_file\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "import glob\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['38_Hannah Wolfe Resume.pdf', '38_Marketing Sales Intern_Job Description.pdf', '52_Garrett Cassells Resume.pdf', '52_Marketing Manager_Job Description.pdf']\n"
          ]
        }
      ],
      "source": [
        "files = glob.glob(\"*.pdf*\")\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Load Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_file = files[2]\n",
        "resume_file = files[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'52_Garrett Cassells Resume.pdf'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple passthrough function\n",
        "# what is this function for?\n",
        "def passthrough(input_data):\n",
        "    return input_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Extract job ad text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GGfUjiiFLHYX",
        "outputId": "6945da54-a41b-49b4-cb67-8ca5e542131d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Garrett Cassells\n",
            "Remote Demand Generation, Sr. Digital Marketer, SEO, PPC, Analytics & Reporting\n",
            "Atlanta, GA  30308\n",
            "GarrettGCassells@gmail.com\n",
            "+1 954 274 3326\n",
            "Demand Generation, Performance Marketing, Digital Marketer, SEO, PPC & Analytics \n",
            "Dynamic Online Marketing Professional with extensive experience in creating compelling digital\n",
            "marketing campaigns to build brands, attract customers and drive revenues. Knowledgeable in all\n",
            "phases of online marketing, from ideation to execution. Skilled at creating strategies that incorporate\n",
            "proven techniques and technologies to achieve a client organization’s objectives. History of delivering\n",
            "results that help businesses expand their audience, generate awareness and increase sales.\n",
            "Authorized to work in the US for any employer\n",
            "Work Experience\n",
            "Demand Generation – Performance Marketing Manager (Contract)\n",
            "The Walt Disney Company (Disney Publishing – eCom)  - Remote\n",
            "May 2021 to Present\n",
            "• Google Ads, Microsoft Ads, Google Shopping, Paid Search, Amazon PPC, YouTube Ads & SEO.\n",
            "• Top Wins: 48.9K Conversions. Reducing Paid Search CPA from $22.71 to $3.71. A MoM ROAS that\n",
            "fluctuated from $8-$12 starting month 3.\n",
            "• Day to Day: Launched & Optimized Performance Marketing Initiatives for The Disney Publishing\n",
            "Division:\n",
            "SR. Digital Marketing Manager: ECOM, SEO, PPC & Shopping\n",
            "The Home Depot  - Remote\n",
            "May 2019 to Present\n",
            "Developed and managed comprehensive online marketing campaigns for several divisions, subsidiaries,\n",
            "and company partners. Projects included Google & Bing paid media campaigns, which were optimized\n",
            "based on real- time opportunities.\n",
            "• Implemented DSA campaigns, which created a site-wide lift for all over 1M SKUs across three brands.\n",
            "• Managed $12M in PPC Ad spend, resulting in $75M in combined online revenues for brand partners\n",
            "including Supply Works, Barnett, Wilmar & Kimberly Clark.\n",
            "• Conduct audits & address technical SEO issues maintaining proper indexing, broken links, 404 errors,\n",
            "301/302 redirects while maintaining proper Canonical Tags, Robotstxt, Meta robot tags & X robots tags.\n",
            "Sr. SEO – Digital Marketing Manager\n",
            "Bank of America\n",
            "September 2017 to May 2019\n",
            "Assembled and managed an SEM Strategist team to create competitive campaigns against Square using\n",
            "SEO,\n",
            "PPC, Facebook and YouTube Ads. Served as SEO subject matter expert to product IT, Dev Ops, and\n",
            "Copywriters, providing SEO recommendations.\n",
            "• Created, managed and executed SEO, SEM, PPC & display campaigns for TOF, MOF & BOF programs.\n",
            "• Performed technical SEO & PPC audits, conversion rate optimization audits, competitor website & SEM\n",
            "audits.\n",
            "• Conducted content gap analysis reports while ensuring lower CPCs, higher CTR and Increasing ROAS\n",
            "Targets.\n",
            "Senior Digital Marketer SEO, PPC Strategist, Digital Analytics\n",
            "Thomson Reuters\n",
            "July 2015 to September 2017\n",
            "Acted as the Digital Strategist for FindLaw, a part of Thomson Reuters, managing PPC and paid search\n",
            "campaigns for over 63 law firms. Created and executed a holistic search strategy (SEO & PPC) supporting\n",
            "the clients’ business objectives. Created lead generation campaigns through consultation form fills and\n",
            "click to call campaigns.\n",
            "• Reduced T-CPA by 30% for CPC’s like “Personal Injury” by creating SKAGS and GEO-Modifiers.\n",
            "• Achieved a PI Case Acquisition cost of $2K.\n",
            "• Generated over 700 new signed personal injury cases within the first five months of the campaign.\n",
            "• Scaled the monthly budget from $60k to $350K.\n",
            "Digital Marketing Manager\n",
            "SEO By Nerds\n",
            "February 2010 to July 2015\n",
            "Directed online marketing activities for over 300 websites and over 5K search terms. Industries included\n",
            "Law\n",
            "Firms, Dental Practices, Medical Offices, Franchises, Multi-Location Businesses and Fortune 100-500\n",
            "companies.\n",
            "• Managed digital campaign assets, landing page development and content, and tracking that support\n",
            "direct response marketing strategy.\n",
            "• Collaborate with marketing team partners to develop new paid search campaign content and messaging\n",
            "to achieve business objectives.\n",
            "• Performed continuous A/B and multivariate testing of campaign messaging and landing pages.\n",
            "• Evaluated and drove qualitative KPIs through continuous improvement and optimization.\n",
            "Education\n",
            "Bachelor of Arts in B.A., Business Administration and Management\n",
            "General Nova Southeastern University\n",
            "Master's degree in Business Administration and management\n",
            "Skills\n",
            "•B2B PPC Lead generation (8 years)\n",
            "•Google Analytics (4 years)\n",
            "•Google AdWords (8 years)\n",
            "•Google Search Console\n",
            "•PPC Campaign Management\n",
            "•Conversion optimization\n",
            "•Content marketing\n",
            "•SEM\n",
            "•SEO\n",
            "•Google Ads\n",
            "•B2B marketing\n",
            "•Adobe Creative Suite\n",
            "•Salesforce\n",
            "•Attribution modeling\n",
            "•Data visualization\n",
            "•Data analytics\n",
            "•Bing Ads (7 years)\n",
            "•Adobe Analytics\n",
            "•Multichannel marketing (6 years)\n",
            "•Media buying (5 years)\n",
            "•Demand Generation Manager (6 years)\n",
            "•Performance Marketing (8 years)\n",
            "•Marketing automation\n",
            "•Analysis skills\n",
            "•CSS\n",
            "•Pardot\n",
            "•HubSpot\n",
            "Links\n",
            "http://linkedin.com/in/garrett-cassells\n",
            "Certifications and Licenses\n",
            "Google AdWords Certification\n",
            "Google Analytics Certification\n",
            "Google Ads Certification\n",
            "\n"
          ]
        }
      ],
      "source": [
        "job_ad_text = extract_text_from_file(job_file)\n",
        "print(job_ad_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Extract resume text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HANNAHWOLFE22006 Philip Drive | Leonardtown, MD 20650 | (301)904-2497 | hwolfe@muhlenberg.edu\n",
            "EDUCATION\n",
            "Leonar dtown Hig h School, Leonar dtown, MDGraduat edMay 2018High School Diploma\n",
            "Muhlenber g College, Allent own, P AExpect ed Gr aduationMay 2022Bachelor of S cienc e, Major in Business A dministr ation \n",
            "●Concentr ation in Mar ketingBachelor of Arts, Media and C ommunications\n",
            "●Current C umulati ve GP A: 3.415\n",
            "SKILLS\n",
            "Comput er Skills: \n",
            "●Experience using man y Adobe pr ograms such as Phot oshop,InDesign, Illustr ator \n",
            "●Ability t o dr aft fl yers, post ers, logos, T -shirt designs,cover art , etc. \n",
            "●Worked with HTML pr ograms such as R studio f or statisticalanal ysis \n",
            "●Proficient using Micr osoft Ex cel\n",
            "WORKEXPERIENCE\n",
            "Breton Ba y Country Club, Leonar dtown, MDJune 2017 – A ugust 2018 (seasonal)Lifeguar d \n",
            "●\n",
            "  CPR Certified thr ough American R ed Cr oss \n",
            "●\n",
            "  In char ge of the saf ety and health of patr ons atBreton Ba y pool, r equir ed team work with others aswellas ability t o tak e char ge in an emer gency \n",
            "●\n",
            "  Help with selling of f ood and drink w hen not inthe guar d stand\n",
            "Refer ence\n",
            " \n",
            ": Ben P eterson (Gener al Manager of Br etonBay Pool)- Cell: (240) 298-5827\n",
            "Ruddy Duck Br ewery & Grill, Do well, MDMay 2019 – A ugust 2019Restaur ant Host ess \n",
            "●\n",
            "  Greeted cust omers and helped t o seat them, managedcash r egist er up fr ont and all t o-go or ders \n",
            "●\n",
            "  Helped bus tables, clean ar ound r estaur ant, andhelped serv e food w hen r estaur ant w as bus y \n",
            "●\n",
            "  Requir ed skills in cust omer service r ealm, pr ofessionalism,and ability t o multitask\n",
            "Refer ence:\n",
            " \n",
            "Niccole Sil ver (Co-o wner of r estaur ant)-Cell: (240) 274-0185\n",
            "Air Combat Eff ectiveness Consulting Gr oup, LL C, Le xingt onPark, MDJune 2020- Pr esentAdministr ative Assistant \n",
            "●Kept tr ack of in ventory f or the A CE office in Le xingt onPark \n",
            "●Took messages f or and dir ected phone calls t o relevantstaff members \n",
            "●Processed and dir ected mail and incoming pack agesor deli veries\n",
            "●Ensur ed that har d copies and digital copies of important financial documents w ere pr oper ly filedand or ganized \n",
            "●Used A dobe Capti vate to con vert P owerPoint tr ainingmodules t o int eractive training modules\n",
            "Refer ence:Thomas Ganse (Compan y Pr esident)- W orkemail:thomas.g anse@acegr oupllc.comCell: (410) 326-5117\n",
            "CAMPUSINVOLVEMENT\n",
            "●Varsity Lacr osse, Muhlenber g College, NCAA Di visionIII \n",
            "●Member of Alpha Phi Omeg a Service F raternity \n",
            "○Executi ve Boar d Position- Vice Pr esident of F ellowship \n",
            "●Member of DCF (DiscipleMak ers Christian F ellowship)Club \n",
            "○Position on Leadership T eam \n",
            "●Freelance gr aphic designer on campus \n",
            "○Has made post ers and logos f or various clubs, students,perf ormers, and Muhlenber gCollege A dmissions\n",
            "AWARDS& HONORS\n",
            "●\n",
            "Earned Gr aphic Design Certification fr om \n",
            " \n",
            "Dr. JamesA. Forrest Car eer & T echnology Cent er in 2017 \n",
            "●Dean ’s List Spring Semest er 2020 at Muhlenber g College \n",
            "●Dean ’s List F all Semest er 2020 at Muhlenber g College\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resume_text = extract_text_from_file(resume_file)\n",
        "print(resume_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "VHEvgCrGLKbJ",
        "outputId": "c6e56d04-bfca-4711-e080-d94c0ac5ba71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/home/james/miniconda3/lib/python3.12/site-packages/transformers/quantizers/auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "BASE_MODEL = '/home/james/models/mistralai/Mistral-7B-Instruct-v0.3'\n",
        "# reference for CustomEmbeddings code?\n",
        "embeddings = CustomEmbeddings(model_name=BASE_MODEL) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# vector_store = FAISS.from_texts(job_ad_text, embedding=embeddings)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(chunks, embedding\u001b[38;5;241m=\u001b[39membeddings)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/langchain_core/vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:931\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    930\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    932\u001b[0m     texts,\n\u001b[1;32m    933\u001b[0m     embeddings,\n\u001b[1;32m    934\u001b[0m     embedding,\n\u001b[1;32m    935\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    936\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    938\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:900\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m index_to_docstore_id \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_to_docstore_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    891\u001b[0m vecstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    892\u001b[0m     embedding,\n\u001b[1;32m    893\u001b[0m     index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    899\u001b[0m )\n\u001b[0;32m--> 900\u001b[0m vecstore\u001b[38;5;241m.\u001b[39m__add(texts, embeddings, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vecstore\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:199\u001b[0m, in \u001b[0;36mFAISS.__add\u001b[0;34m(self, texts, embeddings, metadatas, ids)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_L2:\n\u001b[1;32m    198\u001b[0m     faiss\u001b[38;5;241m.\u001b[39mnormalize_L2(vector)\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39madd(vector)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Add information to docstore and index.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m ids \u001b[38;5;241m=\u001b[39m ids \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/faiss/class_wrappers.py:227\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplacement_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Adds vectors to the index.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    The index must be trained before vectors can be added to it.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    The vectors are implicitly numbered in sequence. When `n` vectors are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m        `dtype` must be float32.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[1;32m    229\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "# vector_store = FAISS.from_texts(job_ad_text, embedding=embeddings)\n",
        "vector_store = FAISS.from_documents(chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your 1 documents have been split into 1 chunks\n"
          ]
        }
      ],
      "source": [
        "file_path = job_file\n",
        "\n",
        "loader = TextLoader(\"temp_text.txt\")\n",
        "data = loader.load()\n",
        "chunk_size = 7500 #1000# 7500\n",
        "chunk_overlap= 100 # 100\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "chunks = text_splitter.split_documents(data)\n",
        "\n",
        "print (f\"Your {len(data)} documents have been split into {len(chunks)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = BM25Retriever(vector_db=job_ad_vectorstore.as_retriever())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your 1 documents have been split into 4 chunks\n"
          ]
        }
      ],
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": passthrough}\n",
        "    | PROMPT\n",
        "    | ChatOllama()\n",
        "    | passthrough  # Simple output parsing\n",
        ")\n",
        "response = chain.invoke(\"Analyze the resume based on the job description\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open(file_path, \"rb\") as f:\n",
        "#     reader = PdfReader(f)\n",
        "#     text = \"\"\n",
        "#     for page in reader.pages:\n",
        "#         text += page.extract_text()\n",
        "#     with open(\"temp_text.txt\", \"w\") as text_file:\n",
        "#         text_file.write(text)\n",
        "#     loader = TextLoader(\"temp_text.txt\")\n",
        "#     data = loader.load()\n",
        "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
        "#     chunks = text_splitter.split_documents(data)\n",
        "#     if chunks:\n",
        "#         embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
        "#         if embeddings_list:\n",
        "#             vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Chroma in module langchain_community.vectorstores.chroma:\n",
            "\n",
            "class Chroma(langchain_core.vectorstores.VectorStore)\n",
            " |  Chroma(collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.Client]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None) -> 'None'\n",
            " |\n",
            " |  `ChromaDB` vector store.\n",
            " |\n",
            " |  To use, you should have the ``chromadb`` python package installed.\n",
            " |\n",
            " |  Example:\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |              from langchain_community.vectorstores import Chroma\n",
            " |              from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
            " |\n",
            " |              embeddings = OpenAIEmbeddings()\n",
            " |              vectorstore = Chroma(\"langchain_store\", embeddings)\n",
            " |\n",
            " |  Method resolution order:\n",
            " |      Chroma\n",
            " |      langchain_core.vectorstores.VectorStore\n",
            " |      abc.ABC\n",
            " |      builtins.object\n",
            " |\n",
            " |  Methods defined here:\n",
            " |\n",
            " |  __init__(self, collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.Client]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None) -> 'None'\n",
            " |      Initialize with a Chroma client.\n",
            " |\n",
            " |  __len__(self) -> 'int'\n",
            " |      Count the number of documents in the collection.\n",
            " |\n",
            " |  add_images(self, uris: 'List[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
            " |      Run more images through the embeddings and add to the vectorstore.\n",
            " |\n",
            " |      Args:\n",
            " |          uris List[str]: File path to the image.\n",
            " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
            " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[str]: List of IDs of the added images.\n",
            " |\n",
            " |  add_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
            " |      Run more texts through the embeddings and add to the vectorstore.\n",
            " |\n",
            " |      Args:\n",
            " |          texts (Iterable[str]): Texts to add to the vectorstore.\n",
            " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
            " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[str]: List of IDs of the added texts.\n",
            " |\n",
            " |  delete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'None'\n",
            " |      Delete by vector IDs.\n",
            " |\n",
            " |      Args:\n",
            " |          ids: List of ids to delete.\n",
            " |\n",
            " |  delete_collection(self) -> 'None'\n",
            " |      Delete the collection.\n",
            " |\n",
            " |  encode_image(self, uri: 'str') -> 'str'\n",
            " |      Get base64 string from image URI.\n",
            " |\n",
            " |  get(self, ids: 'Optional[OneOrMany[ID]]' = None, where: 'Optional[Where]' = None, limit: 'Optional[int]' = None, offset: 'Optional[int]' = None, where_document: 'Optional[WhereDocument]' = None, include: 'Optional[List[str]]' = None) -> 'Dict[str, Any]'\n",
            " |      Gets the collection.\n",
            " |\n",
            " |      Args:\n",
            " |          ids: The ids of the embeddings to get. Optional.\n",
            " |          where: A Where type dict used to filter results by.\n",
            " |                 E.g. `{\"color\" : \"red\", \"price\": 4.20}`. Optional.\n",
            " |          limit: The number of documents to return. Optional.\n",
            " |          offset: The offset to start returning results from.\n",
            " |                  Useful for paging results with limit. Optional.\n",
            " |          where_document: A WhereDocument type dict used to filter by the documents.\n",
            " |                          E.g. `{$contains: \"hello\"}`. Optional.\n",
            " |          include: A list of what to include in the results.\n",
            " |                   Can contain `\"embeddings\"`, `\"metadatas\"`, `\"documents\"`.\n",
            " |                   Ids are always included.\n",
            " |                   Defaults to `[\"metadatas\", \"documents\"]`. Optional.\n",
            " |\n",
            " |  max_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs selected using the maximal marginal relevance.\n",
            " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
            " |      among selected documents.\n",
            " |\n",
            " |      Args:\n",
            " |          query: Text to look up documents similar to.\n",
            " |          k: Number of Documents to return. Defaults to 4.\n",
            " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
            " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
            " |                      of diversity among the results with 0 corresponding\n",
            " |                      to maximum diversity and 1 to minimum diversity.\n",
            " |                      Defaults to 0.5.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          List of Documents selected by maximal marginal relevance.\n",
            " |\n",
            " |  max_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs selected using the maximal marginal relevance.\n",
            " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
            " |      among selected documents.\n",
            " |\n",
            " |      Args:\n",
            " |          embedding: Embedding to look up documents similar to.\n",
            " |          k: Number of Documents to return. Defaults to 4.\n",
            " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
            " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
            " |                      of diversity among the results with 0 corresponding\n",
            " |                      to maximum diversity and 1 to minimum diversity.\n",
            " |                      Defaults to 0.5.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          List of Documents selected by maximal marginal relevance.\n",
            " |\n",
            " |  persist(self) -> 'None'\n",
            " |      [*Deprecated*] Persist the collection.\n",
            " |\n",
            " |      This can be used to explicitly persist the data to disk.\n",
            " |      It will also be called automatically when the object is destroyed.\n",
            " |\n",
            " |      Since Chroma 0.4.x the manual persistence method is no longer\n",
            " |      supported as docs are automatically persisted.\n",
            " |\n",
            " |      Notes\n",
            " |      -----\n",
            " |      .. deprecated:: langchain-community==0.1.17\n",
            " |         Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            " |\n",
            " |  similarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Run similarity search with Chroma.\n",
            " |\n",
            " |      Args:\n",
            " |          query (str): Query text to search for.\n",
            " |          k (int): Number of results to return. Defaults to 4.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[Document]: List of documents most similar to the query text.\n",
            " |\n",
            " |  similarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs most similar to embedding vector.\n",
            " |      Args:\n",
            " |          embedding (List[float]): Embedding to look up documents similar to.\n",
            " |          k (int): Number of Documents to return. Defaults to 4.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |      Returns:\n",
            " |          List of Documents most similar to the query vector.\n",
            " |\n",
            " |  similarity_search_by_vector_with_relevance_scores(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
            " |      Return docs most similar to embedding vector and similarity score.\n",
            " |\n",
            " |      Args:\n",
            " |          embedding (List[float]): Embedding to look up documents similar to.\n",
            " |          k (int): Number of Documents to return. Defaults to 4.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[Tuple[Document, float]]: List of documents most similar to\n",
            " |          the query text and cosine distance in float for each.\n",
            " |          Lower score represents more similarity.\n",
            " |\n",
            " |  similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
            " |      Run similarity search with Chroma with distance.\n",
            " |\n",
            " |      Args:\n",
            " |          query (str): Query text to search for.\n",
            " |          k (int): Number of results to return. Defaults to 4.\n",
            " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[Tuple[Document, float]]: List of documents most similar to\n",
            " |          the query text and cosine distance in float for each.\n",
            " |          Lower score represents more similarity.\n",
            " |\n",
            " |  update_document(self, document_id: 'str', document: 'Document') -> 'None'\n",
            " |      Update a document in the collection.\n",
            " |\n",
            " |      Args:\n",
            " |          document_id (str): ID of the document to update.\n",
            " |          document (Document): Document to update.\n",
            " |\n",
            " |  update_documents(self, ids: 'List[str]', documents: 'List[Document]') -> 'None'\n",
            " |      Update a document in the collection.\n",
            " |\n",
            " |      Args:\n",
            " |          ids (List[str]): List of ids of the document to update.\n",
            " |          documents (List[Document]): List of documents to update.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |\n",
            " |  from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
            " |      Create a Chroma vectorstore from a list of documents.\n",
            " |\n",
            " |      If a persist_directory is specified, the collection will be persisted there.\n",
            " |      Otherwise, the data will be ephemeral in-memory.\n",
            " |\n",
            " |      Args:\n",
            " |          collection_name (str): Name of the collection to create.\n",
            " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
            " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
            " |          documents (List[Document]): List of documents to add to the vectorstore.\n",
            " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
            " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
            " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
            " |                                                Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          Chroma: Chroma vectorstore.\n",
            " |\n",
            " |  from_texts(texts: 'List[str]', embedding: 'Optional[Embeddings]' = None, metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
            " |      Create a Chroma vectorstore from a raw documents.\n",
            " |\n",
            " |      If a persist_directory is specified, the collection will be persisted there.\n",
            " |      Otherwise, the data will be ephemeral in-memory.\n",
            " |\n",
            " |      Args:\n",
            " |          texts (List[str]): List of texts to add to the collection.\n",
            " |          collection_name (str): Name of the collection to create.\n",
            " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
            " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
            " |          metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.\n",
            " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
            " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
            " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
            " |                                                Defaults to None.\n",
            " |\n",
            " |      Returns:\n",
            " |          Chroma: Chroma vectorstore.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |\n",
            " |  embeddings\n",
            " |      Access the query embedding object if available.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |\n",
            " |  __abstractmethods__ = frozenset()\n",
            " |\n",
            " |  __annotations__ = {}\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.vectorstores.VectorStore:\n",
            " |\n",
            " |  async aadd_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
            " |      Run more documents through the embeddings and add to the vectorstore.\n",
            " |\n",
            " |      Args:\n",
            " |          documents (List[Document]: Documents to add to the vectorstore.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[str]: List of IDs of the added texts.\n",
            " |\n",
            " |  async aadd_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
            " |      Run more texts through the embeddings and add to the vectorstore.\n",
            " |\n",
            " |  add_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
            " |      Run more documents through the embeddings and add to the vectorstore.\n",
            " |\n",
            " |      Args:\n",
            " |          documents (List[Document]: Documents to add to the vectorstore.\n",
            " |\n",
            " |      Returns:\n",
            " |          List[str]: List of IDs of the added texts.\n",
            " |\n",
            " |  async adelete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
            " |      Delete by vector ID or other criteria.\n",
            " |\n",
            " |      Args:\n",
            " |          ids: List of ids to delete.\n",
            " |          **kwargs: Other keyword arguments that subclasses might use.\n",
            " |\n",
            " |      Returns:\n",
            " |          Optional[bool]: True if deletion is successful,\n",
            " |          False otherwise, None if not implemented.\n",
            " |\n",
            " |  async amax_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs selected using the maximal marginal relevance.\n",
            " |\n",
            " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
            " |      among selected documents.\n",
            " |\n",
            " |      Args:\n",
            " |          query: Text to look up documents similar to.\n",
            " |          k: Number of Documents to return. Defaults to 4.\n",
            " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
            " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
            " |                      of diversity among the results with 0 corresponding\n",
            " |                      to maximum diversity and 1 to minimum diversity.\n",
            " |                      Defaults to 0.5.\n",
            " |      Returns:\n",
            " |          List of Documents selected by maximal marginal relevance.\n",
            " |\n",
            " |  async amax_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs selected using the maximal marginal relevance.\n",
            " |\n",
            " |  as_retriever(self, **kwargs: 'Any') -> 'VectorStoreRetriever'\n",
            " |      Return VectorStoreRetriever initialized from this VectorStore.\n",
            " |\n",
            " |      Args:\n",
            " |          search_type (Optional[str]): Defines the type of search that\n",
            " |              the Retriever should perform.\n",
            " |              Can be \"similarity\" (default), \"mmr\", or\n",
            " |              \"similarity_score_threshold\".\n",
            " |          search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
            " |              search function. Can include things like:\n",
            " |                  k: Amount of documents to return (Default: 4)\n",
            " |                  score_threshold: Minimum relevance threshold\n",
            " |                      for similarity_score_threshold\n",
            " |                  fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
            " |                  lambda_mult: Diversity of results returned by MMR;\n",
            " |                      1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
            " |                  filter: Filter by document metadata\n",
            " |\n",
            " |      Returns:\n",
            " |          VectorStoreRetriever: Retriever class for VectorStore.\n",
            " |\n",
            " |      Examples:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          # Retrieve more documents with higher diversity\n",
            " |          # Useful if your dataset has many similar documents\n",
            " |          docsearch.as_retriever(\n",
            " |              search_type=\"mmr\",\n",
            " |              search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
            " |          )\n",
            " |\n",
            " |          # Fetch more documents for the MMR algorithm to consider\n",
            " |          # But only return the top 5\n",
            " |          docsearch.as_retriever(\n",
            " |              search_type=\"mmr\",\n",
            " |              search_kwargs={'k': 5, 'fetch_k': 50}\n",
            " |          )\n",
            " |\n",
            " |          # Only retrieve documents that have a relevance score\n",
            " |          # Above a certain threshold\n",
            " |          docsearch.as_retriever(\n",
            " |              search_type=\"similarity_score_threshold\",\n",
            " |              search_kwargs={'score_threshold': 0.8}\n",
            " |          )\n",
            " |\n",
            " |          # Only get the single most similar document from the dataset\n",
            " |          docsearch.as_retriever(search_kwargs={'k': 1})\n",
            " |\n",
            " |          # Use a filter to only retrieve documents from a specific paper\n",
            " |          docsearch.as_retriever(\n",
            " |              search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
            " |          )\n",
            " |\n",
            " |  async asearch(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs most similar to query using specified search type.\n",
            " |\n",
            " |  async asimilarity_search(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs most similar to query.\n",
            " |\n",
            " |  async asimilarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs most similar to embedding vector.\n",
            " |\n",
            " |  async asimilarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
            " |      Return docs and relevance scores in the range [0, 1], asynchronously.\n",
            " |\n",
            " |      0 is dissimilar, 1 is most similar.\n",
            " |\n",
            " |      Args:\n",
            " |          query: input text\n",
            " |          k: Number of Documents to return. Defaults to 4.\n",
            " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
            " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
            " |                  filter the resulting set of retrieved docs\n",
            " |\n",
            " |      Returns:\n",
            " |          List of Tuples of (doc, similarity_score)\n",
            " |\n",
            " |  async asimilarity_search_with_score(self, *args: 'Any', **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
            " |      Run similarity search with distance asynchronously.\n",
            " |\n",
            " |  search(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Return docs most similar to query using specified search type.\n",
            " |\n",
            " |  similarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
            " |      Return docs and relevance scores in the range [0, 1].\n",
            " |\n",
            " |      0 is dissimilar, 1 is most similar.\n",
            " |\n",
            " |      Args:\n",
            " |          query: input text\n",
            " |          k: Number of Documents to return. Defaults to 4.\n",
            " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
            " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
            " |                  filter the resulting set of retrieved docs\n",
            " |\n",
            " |      Returns:\n",
            " |          List of Tuples of (doc, similarity_score)\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.vectorstores.VectorStore:\n",
            " |\n",
            " |  async afrom_documents(documents: 'List[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
            " |      Return VectorStore initialized from documents and embeddings.\n",
            " |\n",
            " |  async afrom_texts(texts: 'List[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
            " |      Return VectorStore initialized from texts and embeddings.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from langchain_core.vectorstores.VectorStore:\n",
            " |\n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |\n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(Chroma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name='/home/james/models/BAAI/bge-base-en-v1.5',\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'job_file' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# file_path = resume_file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m job_file\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     reader \u001b[38;5;241m=\u001b[39m PdfReader(f)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'job_file' is not defined"
          ]
        }
      ],
      "source": [
        "# file_path = resume_file\n",
        "file_path = job_file\n",
        "\n",
        "with open(file_path, \"rb\") as f:\n",
        "    reader = PdfReader(f)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    with open(\"temp_text.txt\", \"w\") as text_file:\n",
        "        text_file.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Garrett Cassells\\nRemote Demand Generation, Sr. Digital Marketer, SEO, PPC, Analytics & Reporting\\nAtlanta, GA  30308\\nGarrettGCassells@gmail.com\\n+1 954 274 3326\\nDemand Generation, Performance Marketing, Digital Marketer, SEO, PPC & Analytics\\xa0\\nDynamic Online Marketing Professional with extensive experience in creating compelling digital\\nmarketing campaigns to build brands, attract customers and drive revenues. Knowledgeable in all\\nphases of online marketing, from ideation to execution. Skilled at creating strategies that incorporate\\nproven techniques and technologies to achieve a client organization’s objectives. History of delivering\\nresults that help businesses expand their audience, generate awareness and increase sales.\\nAuthorized to work in the US for any employer\\nWork Experience\\nDemand Generation – Performance Marketing Manager (Contract)\\nThe Walt Disney Company (Disney Publishing – eCom)  - Remote\\nMay 2021 to Present\\n• Google Ads, Microsoft Ads, Google Shopping, Paid Search, Amazon PPC, YouTube Ads & SEO.\\n• Top Wins: 48.9K Conversions. Reducing Paid Search CPA from $22.71 to $3.71. A MoM ROAS that\\nfluctuated from $8-$12 starting month 3.\\n• Day to Day: Launched & Optimized Performance Marketing Initiatives for The Disney Publishing\\nDivision:\\nSR. Digital Marketing Manager: ECOM, SEO, PPC & Shopping\\nThe Home Depot  - Remote\\nMay 2019 to Present\\nDeveloped and managed comprehensive online marketing campaigns for several divisions, subsidiaries,\\nand company partners. Projects included Google & Bing paid media campaigns, which were optimized\\nbased on real- time opportunities.\\n• Implemented DSA campaigns, which created a site-wide lift for all over 1M SKUs across three brands.\\n• Managed $12M in PPC Ad spend, resulting in $75M in combined online revenues for brand partners\\nincluding Supply Works, Barnett, Wilmar & Kimberly Clark.\\n• Conduct audits & address technical SEO issues maintaining proper indexing, broken links, 404 errors,\\n301/302 redirects while maintaining proper Canonical Tags, Robotstxt, Meta robot tags & X robots tags.\\nSr. SEO – Digital Marketing Manager\\nBank of America\\nSeptember 2017 to May 2019\\nAssembled and managed an SEM Strategist team to create competitive campaigns against Square using\\nSEO,\\nPPC, Facebook and YouTube Ads. Served as SEO subject matter expert to product IT, Dev Ops, and\\nCopywriters, providing SEO recommendations.\\n• Created, managed and executed SEO, SEM, PPC & display campaigns for TOF, MOF & BOF programs.• Performed technical SEO & PPC audits, conversion rate optimization audits, competitor website & SEM\\naudits.\\n• Conducted content gap analysis reports while ensuring lower CPCs, higher CTR and Increasing ROAS\\nTargets.\\nSenior Digital Marketer SEO, PPC Strategist, Digital Analytics\\nThomson Reuters\\nJuly 2015 to September 2017\\nActed as the Digital Strategist for FindLaw, a part of Thomson Reuters, managing PPC and paid search\\ncampaigns for over 63 law firms. Created and executed a holistic search strategy (SEO & PPC) supporting\\nthe clients’ business objectives. Created lead generation campaigns through consultation form fills and\\nclick to call campaigns.\\n• Reduced T-CPA by 30% for CPC’s like “Personal Injury” by creating SKAGS and GEO-Modifiers.\\n• Achieved a PI Case Acquisition cost of $2K.\\n• Generated over 700 new signed personal injury cases within the first five months of the campaign.\\n• Scaled the monthly budget from $60k to $350K.\\nDigital Marketing Manager\\nSEO By Nerds\\nFebruary 2010 to July 2015\\nDirected online marketing activities for over 300 websites and over 5K search terms. Industries included\\nLaw\\nFirms, Dental Practices, Medical Offices, Franchises, Multi-Location Businesses and Fortune 100-500\\ncompanies.\\n• Managed digital campaign assets, landing page development and content, and tracking that support\\ndirect response marketing strategy.\\n• Collaborate with marketing team partners to develop new paid search campaign content and messaging\\nto achieve business objectives.\\n• Performed continuous A/B and multivariate testing of campaign messaging and landing pages.\\n• Evaluated and drove qualitative KPIs through continuous improvement and optimization.\\nEducation\\nBachelor of Arts in B.A., Business Administration and Management\\nGeneral Nova Southeastern University\\nMaster's degree in Business Administration and management\\nSkills\\n•B2B PPC Lead generation (8 years)\\n•Google Analytics (4 years)\\n•Google AdWords (8 years)\\n•Google Search Console\\n•PPC Campaign Management\\n•Conversion optimization•Content marketing\\n•SEM\\n•SEO\\n•Google Ads\\n•B2B marketing\\n•Adobe Creative Suite\\n•Salesforce\\n•Attribution modeling\\n•Data visualization\\n•Data analytics\\n•Bing Ads (7 years)\\n•Adobe Analytics\\n•Multichannel marketing (6 years)\\n•Media buying (5 years)\\n•Demand Generation Manager (6 years)\\n•Performance Marketing (8 years)\\n•Marketing automation\\n•Analysis skills\\n•CSS\\n•Pardot\\n•HubSpot\\nLinks\\nhttp://linkedin.com/in/garrett-cassells\\nCertifications and Licenses\\nGoogle AdWords Certification\\nGoogle Analytics Certification\\nGoogle Ads Certification\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = TextLoader(\"temp_text.txt\")\n",
        "data = loader.load()\n",
        "chunk_size = 100# 7500\n",
        "chunk_overlap= 10 # 100\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "chunks = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your 1 documents have been split into 74 chunks\n"
          ]
        }
      ],
      "source": [
        "print (f\"Your {len(data)} documents have been split into {len(chunks)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"Garrett Cassells\\nRemote Demand Generation, Sr. Digital Marketer, SEO, PPC, Analytics & Reporting\\nAtlanta, GA  30308\\nGarrettGCassells@gmail.com\\n+1 954 274 3326\\nDemand Generation, Performance Marketing, Digital Marketer, SEO, PPC & Analytics\\xa0\\nDynamic Online Marketing Professional with extensive experience in creating compelling digital\\nmarketing campaigns to build brands, attract customers and drive revenues. Knowledgeable in all\\nphases of online marketing, from ideation to execution. Skilled at creating strategies that incorporate\\nproven techniques and technologies to achieve a client organization’s objectives. History of delivering\\nresults that help businesses expand their audience, generate awareness and increase sales.\\nAuthorized to work in the US for any employer\\nWork Experience\\nDemand Generation – Performance Marketing Manager (Contract)\\nThe Walt Disney Company (Disney Publishing – eCom)  - Remote\\nMay 2021 to Present\\n• Google Ads, Microsoft Ads, Google Shopping, Paid Search, Amazon PPC, YouTube Ads & SEO.\\n• Top Wins: 48.9K Conversions. Reducing Paid Search CPA from $22.71 to $3.71. A MoM ROAS that\\nfluctuated from $8-$12 starting month 3.\\n• Day to Day: Launched & Optimized Performance Marketing Initiatives for The Disney Publishing\\nDivision:\\nSR. Digital Marketing Manager: ECOM, SEO, PPC & Shopping\\nThe Home Depot  - Remote\\nMay 2019 to Present\\nDeveloped and managed comprehensive online marketing campaigns for several divisions, subsidiaries,\\nand company partners. Projects included Google & Bing paid media campaigns, which were optimized\\nbased on real- time opportunities.\\n• Implemented DSA campaigns, which created a site-wide lift for all over 1M SKUs across three brands.\\n• Managed $12M in PPC Ad spend, resulting in $75M in combined online revenues for brand partners\\nincluding Supply Works, Barnett, Wilmar & Kimberly Clark.\\n• Conduct audits & address technical SEO issues maintaining proper indexing, broken links, 404 errors,\\n301/302 redirects while maintaining proper Canonical Tags, Robotstxt, Meta robot tags & X robots tags.\\nSr. SEO – Digital Marketing Manager\\nBank of America\\nSeptember 2017 to May 2019\\nAssembled and managed an SEM Strategist team to create competitive campaigns against Square using\\nSEO,\\nPPC, Facebook and YouTube Ads. Served as SEO subject matter expert to product IT, Dev Ops, and\\nCopywriters, providing SEO recommendations.\\n• Created, managed and executed SEO, SEM, PPC & display campaigns for TOF, MOF & BOF programs.• Performed technical SEO & PPC audits, conversion rate optimization audits, competitor website & SEM\\naudits.\\n• Conducted content gap analysis reports while ensuring lower CPCs, higher CTR and Increasing ROAS\\nTargets.\\nSenior Digital Marketer SEO, PPC Strategist, Digital Analytics\\nThomson Reuters\\nJuly 2015 to September 2017\\nActed as the Digital Strategist for FindLaw, a part of Thomson Reuters, managing PPC and paid search\\ncampaigns for over 63 law firms. Created and executed a holistic search strategy (SEO & PPC) supporting\\nthe clients’ business objectives. Created lead generation campaigns through consultation form fills and\\nclick to call campaigns.\\n• Reduced T-CPA by 30% for CPC’s like “Personal Injury” by creating SKAGS and GEO-Modifiers.\\n• Achieved a PI Case Acquisition cost of $2K.\\n• Generated over 700 new signed personal injury cases within the first five months of the campaign.\\n• Scaled the monthly budget from $60k to $350K.\\nDigital Marketing Manager\\nSEO By Nerds\\nFebruary 2010 to July 2015\\nDirected online marketing activities for over 300 websites and over 5K search terms. Industries included\\nLaw\\nFirms, Dental Practices, Medical Offices, Franchises, Multi-Location Businesses and Fortune 100-500\\ncompanies.\\n• Managed digital campaign assets, landing page development and content, and tracking that support\\ndirect response marketing strategy.\\n• Collaborate with marketing team partners to develop new paid search campaign content and messaging\\nto achieve business objectives.\\n• Performed continuous A/B and multivariate testing of campaign messaging and landing pages.\\n• Evaluated and drove qualitative KPIs through continuous improvement and optimization.\\nEducation\\nBachelor of Arts in B.A., Business Administration and Management\\nGeneral Nova Southeastern University\\nMaster's degree in Business Administration and management\\nSkills\\n•B2B PPC Lead generation (8 years)\\n•Google Analytics (4 years)\\n•Google AdWords (8 years)\\n•Google Search Console\\n•PPC Campaign Management\\n•Conversion optimization•Content marketing\\n•SEM\\n•SEO\\n•Google Ads\\n•B2B marketing\\n•Adobe Creative Suite\\n•Salesforce\\n•Attribution modeling\\n•Data visualization\\n•Data analytics\\n•Bing Ads (7 years)\\n•Adobe Analytics\\n•Multichannel marketing (6 years)\\n•Media buying (5 years)\\n•Demand Generation Manager (6 years)\\n•Performance Marketing (8 years)\\n•Marketing automation\\n•Analysis skills\\n•CSS\\n•Pardot\\n•HubSpot\\nLinks\\nhttp://linkedin.com/in/garrett-cassells\\nCertifications and Licenses\\nGoogle AdWords Certification\\nGoogle Analytics Certification\\nGoogle Ads Certification\", metadata={'source': 'temp_text.txt'})]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/transformers/quantizers/auto.py:155: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"job_file_docs\",\n",
        "    embedding_function=CustomEmbeddings(model_name=BASE_MODEL)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "\n",
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore, \n",
        "    docstore=store, \n",
        "    child_splitter=text_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "retriever.add_documents(data, ids=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tools.CustomEmbeddings at 0x7fd82c287500>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# db._collection.get(include=['embeddings'])\n",
        "# embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if chunks:\n",
        "#     embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
        "#     if embeddings_list:\n",
        "#         vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# file_path = resume_file\n",
        "file_path = job_file\n",
        "with open(file_path, \"rb\") as f:\n",
        "    reader = PdfReader(f)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    with open(\"temp_text.txt\", \"w\") as text_file:\n",
        "        text_file.write(text)\n",
        "    loader = TextLoader(\"temp_text.txt\")\n",
        "    data = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "    if chunks:\n",
        "        embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
        "        if embeddings_list:\n",
        "            vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_vectorstore = vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "file_path = resume_file\n",
        "# file_path = job_file\n",
        "with open(file_path, \"rb\") as f:\n",
        "    reader = PdfReader(f)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    with open(\"temp_text.txt\", \"w\") as text_file:\n",
        "        text_file.write(text)\n",
        "    loader = TextLoader(\"temp_text.txt\")\n",
        "    data = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "    if chunks:\n",
        "        embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
        "        if embeddings_list:\n",
        "            vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "resume_vectorstore = vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f50bfb385c0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retriever = BM25Retriever(vector_db=job_vectorstore.as_retriever())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class BM25Retriever in module langchain_community.retrievers.bm25:\n",
            "\n",
            "class BM25Retriever(langchain_core.retrievers.BaseRetriever)\n",
            " |  BM25Retriever(*, name: Optional[str] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, vectorizer: Any = None, docs: List[langchain_core.documents.base.Document], k: int = 4, preprocess_func: Callable[[str], List[str]] = <function default_preprocessing_func at 0x7f517dd46980>) -> None\n",
            " |\n",
            " |  `BM25` retriever without Elasticsearch.\n",
            " |\n",
            " |  Method resolution order:\n",
            " |      BM25Retriever\n",
            " |      langchain_core.retrievers.BaseRetriever\n",
            " |      langchain_core.runnables.base.RunnableSerializable\n",
            " |      langchain_core.load.serializable.Serializable\n",
            " |      pydantic.v1.main.BaseModel\n",
            " |      pydantic.v1.utils.Representation\n",
            " |      langchain_core.runnables.base.Runnable\n",
            " |      typing.Generic\n",
            " |      abc.ABC\n",
            " |      builtins.object\n",
            " |\n",
            " |  Class methods defined here:\n",
            " |\n",
            " |  from_documents(documents: 'Iterable[Document]', *, bm25_params: 'Optional[Dict[str, Any]]' = None, preprocess_func: 'Callable[[str], List[str]]' = <function default_preprocessing_func at 0x7f517dd46980>, **kwargs: 'Any') -> 'BM25Retriever' from pydantic.v1.main.ModelMetaclass\n",
            " |      Create a BM25Retriever from a list of Documents.\n",
            " |      Args:\n",
            " |          documents: A list of Documents to vectorize.\n",
            " |          bm25_params: Parameters to pass to the BM25 vectorizer.\n",
            " |          preprocess_func: A function to preprocess each text before vectorization.\n",
            " |          **kwargs: Any other arguments to pass to the retriever.\n",
            " |\n",
            " |      Returns:\n",
            " |          A BM25Retriever instance.\n",
            " |\n",
            " |  from_texts(texts: 'Iterable[str]', metadatas: 'Optional[Iterable[dict]]' = None, bm25_params: 'Optional[Dict[str, Any]]' = None, preprocess_func: 'Callable[[str], List[str]]' = <function default_preprocessing_func at 0x7f517dd46980>, **kwargs: 'Any') -> 'BM25Retriever' from pydantic.v1.main.ModelMetaclass\n",
            " |      Create a BM25Retriever from a list of texts.\n",
            " |      Args:\n",
            " |          texts: A list of texts to vectorize.\n",
            " |          metadatas: A list of metadata dicts to associate with each text.\n",
            " |          bm25_params: Parameters to pass to the BM25 vectorizer.\n",
            " |          preprocess_func: A function to preprocess each text before vectorization.\n",
            " |          **kwargs: Any other arguments to pass to the retriever.\n",
            " |\n",
            " |      Returns:\n",
            " |          A BM25Retriever instance.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |\n",
            " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |\n",
            " |  Config = <class 'langchain_community.retrievers.bm25.BM25Retriever.Con...\n",
            " |      Configuration for this pydantic object.\n",
            " |\n",
            " |\n",
            " |  __abstractmethods__ = frozenset()\n",
            " |\n",
            " |  __annotations__ = {'docs': 'List[Document]', 'k': 'int', 'preprocess_f...\n",
            " |\n",
            " |  __class_vars__ = set()\n",
            " |\n",
            " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
            " |\n",
            " |  __custom_root_type__ = False\n",
            " |\n",
            " |  __exclude_fields__ = None\n",
            " |\n",
            " |  __fields__ = {'docs': ModelField(name='docs', type=List[Document], req...\n",
            " |\n",
            " |  __hash__ = None\n",
            " |\n",
            " |  __include_fields__ = None\n",
            " |\n",
            " |  __parameters__ = ()\n",
            " |\n",
            " |  __post_root_validators__ = []\n",
            " |\n",
            " |  __pre_root_validators__ = []\n",
            " |\n",
            " |  __private_attributes__ = {}\n",
            " |\n",
            " |  __schema_cache__ = {}\n",
            " |\n",
            " |  __signature__ = <Signature (*, name: Optional[str] = None, tags:...t_p...\n",
            " |\n",
            " |  __validators__ = {}\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.retrievers.BaseRetriever:\n",
            " |\n",
            " |  async aget_relevant_documents(self, query: 'str', *, callbacks: 'Callbacks' = None, tags: 'Optional[List[str]]' = None, metadata: 'Optional[Dict[str, Any]]' = None, run_name: 'Optional[str]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      [*Deprecated*] Asynchronously get documents relevant to a query.\n",
            " |\n",
            " |      Users should favor using `.ainvoke` or `.abatch` rather than\n",
            " |      `aget_relevant_documents directly`.\n",
            " |\n",
            " |      Args:\n",
            " |          query: string to find relevant documents for\n",
            " |          callbacks: Callback manager or list of callbacks\n",
            " |          tags: Optional list of tags associated with the retriever. Defaults to None\n",
            " |              These tags will be associated with each call to this retriever,\n",
            " |              and passed as arguments to the handlers defined in `callbacks`.\n",
            " |          metadata: Optional metadata associated with the retriever. Defaults to None\n",
            " |              This metadata will be associated with each call to this retriever,\n",
            " |              and passed as arguments to the handlers defined in `callbacks`.\n",
            " |          run_name: Optional name for the run.\n",
            " |\n",
            " |      Returns:\n",
            " |          List of relevant documents\n",
            " |\n",
            " |      Notes\n",
            " |      -----\n",
            " |      .. deprecated:: langchain-core==0.1.46\n",
            " |         Use ainvoke instead.\n",
            " |\n",
            " |  async ainvoke(self, input: 'str', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Asynchronously invoke the retriever to get relevant documents.\n",
            " |\n",
            " |      Main entry point for asynchronous retriever invocations.\n",
            " |\n",
            " |      Args:\n",
            " |          input: The query string\n",
            " |          config: Configuration for the retriever\n",
            " |          **kwargs: Additional arguments to pass to the retriever\n",
            " |\n",
            " |      Returns:\n",
            " |          List of relevant documents\n",
            " |\n",
            " |      Examples:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          await retriever.ainvoke(\"query\")\n",
            " |\n",
            " |  get_relevant_documents(self, query: 'str', *, callbacks: 'Callbacks' = None, tags: 'Optional[List[str]]' = None, metadata: 'Optional[Dict[str, Any]]' = None, run_name: 'Optional[str]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      [*Deprecated*] Retrieve documents relevant to a query.\n",
            " |\n",
            " |      Users should favor using `.invoke` or `.batch` rather than\n",
            " |      `get_relevant_documents directly`.\n",
            " |\n",
            " |      Args:\n",
            " |          query: string to find relevant documents for\n",
            " |          callbacks: Callback manager or list of callbacks\n",
            " |          tags: Optional list of tags associated with the retriever. Defaults to None\n",
            " |              These tags will be associated with each call to this retriever,\n",
            " |              and passed as arguments to the handlers defined in `callbacks`.\n",
            " |          metadata: Optional metadata associated with the retriever. Defaults to None\n",
            " |              This metadata will be associated with each call to this retriever,\n",
            " |              and passed as arguments to the handlers defined in `callbacks`.\n",
            " |          run_name: Optional name for the run.\n",
            " |\n",
            " |      Returns:\n",
            " |          List of relevant documents\n",
            " |\n",
            " |      Notes\n",
            " |      -----\n",
            " |      .. deprecated:: langchain-core==0.1.46\n",
            " |         Use invoke instead.\n",
            " |\n",
            " |  invoke(self, input: 'str', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
            " |      Invoke the retriever to get relevant documents.\n",
            " |\n",
            " |      Main entry point for synchronous retriever invocations.\n",
            " |\n",
            " |      Args:\n",
            " |          input: The query string\n",
            " |          config: Configuration for the retriever\n",
            " |          **kwargs: Additional arguments to pass to the retriever\n",
            " |\n",
            " |      Returns:\n",
            " |          List of relevant documents\n",
            " |\n",
            " |      Examples:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          retriever.invoke(\"query\")\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.retrievers.BaseRetriever:\n",
            " |\n",
            " |  __init_subclass__(**kwargs: 'Any') -> 'None' from pydantic.v1.main.ModelMetaclass\n",
            " |      Function to initialize subclasses.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from langchain_core.retrievers.BaseRetriever:\n",
            " |\n",
            " |  __orig_bases__ = (langchain_core.runnables.base.RunnableSerializab...i...\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:\n",
            " |\n",
            " |  configurable_alternatives(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -> 'RunnableSerializable[Input, Output]'\n",
            " |      Configure alternatives for runnables that can be set at runtime.\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_anthropic import ChatAnthropic\n",
            " |          from langchain_core.runnables.utils import ConfigurableField\n",
            " |          from langchain_openai import ChatOpenAI\n",
            " |\n",
            " |          model = ChatAnthropic(\n",
            " |              model_name=\"claude-3-sonnet-20240229\"\n",
            " |          ).configurable_alternatives(\n",
            " |              ConfigurableField(id=\"llm\"),\n",
            " |              default_key=\"anthropic\",\n",
            " |              openai=ChatOpenAI()\n",
            " |          )\n",
            " |\n",
            " |          # uses the default model ChatAnthropic\n",
            " |          print(model.invoke(\"which organization created you?\").content)\n",
            " |\n",
            " |          # uses ChatOpenAI\n",
            " |          print(\n",
            " |              model.with_config(\n",
            " |                  configurable={\"llm\": \"openai\"}\n",
            " |              ).invoke(\"which organization created you?\").content\n",
            " |          )\n",
            " |\n",
            " |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'\n",
            " |      Configure particular runnable fields at runtime.\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_core.runnables import ConfigurableField\n",
            " |          from langchain_openai import ChatOpenAI\n",
            " |\n",
            " |          model = ChatOpenAI(max_tokens=20).configurable_fields(\n",
            " |              max_tokens=ConfigurableField(\n",
            " |                  id=\"output_token_number\",\n",
            " |                  name=\"Max tokens in the output\",\n",
            " |                  description=\"The maximum number of tokens in the output\",\n",
            " |              )\n",
            " |          )\n",
            " |\n",
            " |          # max_tokens = 20\n",
            " |          print(\n",
            " |              \"max_tokens_20: \",\n",
            " |              model.invoke(\"tell me something about chess\").content\n",
            " |          )\n",
            " |\n",
            " |          # max_tokens = 200\n",
            " |          print(\"max_tokens_200: \", model.with_config(\n",
            " |              configurable={\"output_token_number\": 200}\n",
            " |              ).invoke(\"tell me something about chess\").content\n",
            " |          )\n",
            " |\n",
            " |  to_json(self) -> 'Union[SerializedConstructor, SerializedNotImplemented]'\n",
            " |      Serialize the runnable to JSON.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from langchain_core.runnables.base.RunnableSerializable:\n",
            " |\n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
            " |\n",
            " |  __repr_args__(self) -> Any\n",
            " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
            " |\n",
            " |      Can either return:\n",
            " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
            " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
            " |\n",
            " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
            " |\n",
            " |  get_lc_namespace() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
            " |      Get the namespace of the langchain object.\n",
            " |\n",
            " |      For example, if the class is `langchain.llms.openai.OpenAI`, then the\n",
            " |      namespace is [\"langchain\", \"llms\", \"openai\"]\n",
            " |\n",
            " |  is_lc_serializable() -> bool from pydantic.v1.main.ModelMetaclass\n",
            " |      Is this class serializable?\n",
            " |\n",
            " |  lc_id() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
            " |      A unique identifier for this class for serialization purposes.\n",
            " |\n",
            " |      The unique identifier is a list of strings that describes the path\n",
            " |      to the object.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
            " |\n",
            " |  lc_attributes\n",
            " |      List of attribute names that should be included in the serialized kwargs.\n",
            " |\n",
            " |      These attributes must be accepted by the constructor.\n",
            " |\n",
            " |  lc_secrets\n",
            " |      A map of constructor argument names to secret ids.\n",
            " |\n",
            " |      For example,\n",
            " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
            " |\n",
            " |  __eq__(self, other: Any) -> bool\n",
            " |      Return self==value.\n",
            " |\n",
            " |  __getstate__(self) -> 'DictAny'\n",
            " |      Helper for pickle.\n",
            " |\n",
            " |  __init__(__pydantic_self__, **data: Any) -> None\n",
            " |      Create a new model by parsing and validating input data from keyword arguments.\n",
            " |\n",
            " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
            " |\n",
            " |  __iter__(self) -> 'TupleGenerator'\n",
            " |      so `dict(model)` works\n",
            " |\n",
            " |  __setattr__(self, name, value)\n",
            " |      Implement setattr(self, name, value).\n",
            " |\n",
            " |  __setstate__(self, state: 'DictAny') -> None\n",
            " |\n",
            " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
            " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
            " |\n",
            " |      :param include: fields to include in new model\n",
            " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
            " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
            " |          the new model: you should trust this data\n",
            " |      :param deep: set to `True` to make a deep copy of the model\n",
            " |      :return: new model instance\n",
            " |\n",
            " |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
            " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
            " |\n",
            " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> str\n",
            " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
            " |\n",
            " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
            " |\n",
            " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Same as update_forward_refs but will not raise exception\n",
            " |      when forward references are not defined.\n",
            " |\n",
            " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
            " |      Default values are respected, but no other validation is performed.\n",
            " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
            " |\n",
            " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
            " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
            " |\n",
            " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
            " |\n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |\n",
            " |  __fields_set__\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.v1.utils.Representation:\n",
            " |\n",
            " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
            " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
            " |\n",
            " |  __repr__(self) -> str\n",
            " |      Return repr(self).\n",
            " |\n",
            " |  __repr_name__(self) -> str\n",
            " |      Name of the instance's class, used in __repr__.\n",
            " |\n",
            " |  __repr_str__(self, join_str: str) -> str\n",
            " |\n",
            " |  __rich_repr__(self) -> 'RichReprResult'\n",
            " |      Get fields for Rich library\n",
            " |\n",
            " |  __str__(self) -> str\n",
            " |      Return str(self).\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from langchain_core.runnables.base.Runnable:\n",
            " |\n",
            " |  __or__(self, other: 'Union[Runnable[Any, Other], Callable[[Any], Other], Callable[[Iterator[Any]], Iterator[Other]], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -> 'RunnableSerializable[Input, Other]'\n",
            " |      Compose this runnable with another object to create a RunnableSequence.\n",
            " |\n",
            " |  __ror__(self, other: 'Union[Runnable[Other, Any], Callable[[Other], Any], Callable[[Iterator[Other]], Iterator[Any]], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -> 'RunnableSerializable[Other, Output]'\n",
            " |      Compose this runnable with another object to create a RunnableSequence.\n",
            " |\n",
            " |  async abatch(self, inputs: 'List[Input]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'List[Output]'\n",
            " |      Default implementation runs ainvoke in parallel using asyncio.gather.\n",
            " |\n",
            " |      The default implementation of batch works well for IO bound runnables.\n",
            " |\n",
            " |      Subclasses should override this method if they can batch more efficiently;\n",
            " |      e.g., if the underlying runnable uses an API which supports a batch mode.\n",
            " |\n",
            " |  async abatch_as_completed(self, inputs: 'List[Input]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Tuple[int, Union[Output, Exception]]]'\n",
            " |      Run ainvoke in parallel on a list of inputs,\n",
            " |      yielding results as they complete.\n",
            " |\n",
            " |  assign(self, **kwargs: 'Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any], Mapping[str, Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]]]]') -> 'RunnableSerializable[Any, Any]'\n",
            " |      Assigns new fields to the dict output of this runnable.\n",
            " |      Returns a new runnable.\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_community.llms.fake import FakeStreamingListLLM\n",
            " |          from langchain_core.output_parsers import StrOutputParser\n",
            " |          from langchain_core.prompts import SystemMessagePromptTemplate\n",
            " |          from langchain_core.runnables import Runnable\n",
            " |          from operator import itemgetter\n",
            " |\n",
            " |          prompt = (\n",
            " |              SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
            " |              + \"{question}\"\n",
            " |          )\n",
            " |          llm = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
            " |\n",
            " |          chain: Runnable = prompt | llm | {\"str\": StrOutputParser()}\n",
            " |\n",
            " |          chain_with_assign = chain.assign(hello=itemgetter(\"str\") | llm)\n",
            " |\n",
            " |          print(chain_with_assign.input_schema.schema())\n",
            " |          # {'title': 'PromptInput', 'type': 'object', 'properties':\n",
            " |          {'question': {'title': 'Question', 'type': 'string'}}}\n",
            " |          print(chain_with_assign.output_schema.schema()) #\n",
            " |          {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':\n",
            " |          {'str': {'title': 'Str',\n",
            " |          'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}\n",
            " |\n",
            " |  async astream(self, input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
            " |      Default implementation of astream, which calls ainvoke.\n",
            " |      Subclasses should override this method if they support streaming output.\n",
            " |\n",
            " |  astream_events(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, version: \"Literal['v1', 'v2']\", include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[StreamEvent]'\n",
            " |      [*Beta*] Generate a stream of events.\n",
            " |\n",
            " |      Use to create an iterator over StreamEvents that provide real-time information\n",
            " |      about the progress of the runnable, including StreamEvents from intermediate\n",
            " |      results.\n",
            " |\n",
            " |      A StreamEvent is a dictionary with the following schema:\n",
            " |\n",
            " |      - ``event``: **str** - Event names are of the\n",
            " |          format: on_[runnable_type]_(start|stream|end).\n",
            " |      - ``name``: **str** - The name of the runnable that generated the event.\n",
            " |      - ``run_id``: **str** - randomly generated ID associated with the given execution of\n",
            " |          the runnable that emitted the event.\n",
            " |          A child runnable that gets invoked as part of the execution of a\n",
            " |          parent runnable is assigned its own unique ID.\n",
            " |      - ``tags``: **Optional[List[str]]** - The tags of the runnable that generated\n",
            " |          the event.\n",
            " |      - ``metadata``: **Optional[Dict[str, Any]]** - The metadata of the runnable\n",
            " |          that generated the event.\n",
            " |      - ``data``: **Dict[str, Any]**\n",
            " |\n",
            " |\n",
            " |      Below is a table that illustrates some evens that might be emitted by various\n",
            " |      chains. Metadata fields have been omitted from the table for brevity.\n",
            " |      Chain definitions have been included after the table.\n",
            " |\n",
            " |      **ATTENTION** This reference table is for the V2 version of the schema.\n",
            " |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | event                | name             | chunk                           | input                                         | output                                          |\n",
            " |      +======================+==================+=================================+===============================================+=================================================+\n",
            " |      | on_chat_model_start  | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chat_model_stream | [model name]     | AIMessageChunk(content=\"hello\") |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chat_model_end    | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} | AIMessageChunk(content=\"hello world\")           |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_llm_end           | [model name]     |                                 | 'Hello human!'                                |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_tool_start        | some_tool        |                                 | {\"x\": 1, \"y\": \"2\"}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_tool_end          | some_tool        |                                 |                                               | {\"x\": 1, \"y\": \"2\"}                              |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_retriever_start   | [retriever name] |                                 | {\"query\": \"hello\"}                            |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_retriever_end     | [retriever name] |                                 | {\"query\": \"hello\"}                            | [Document(...), ..]                             |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_prompt_start      | [template_name]  |                                 | {\"question\": \"hello\"}                         |                                                 |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |      | on_prompt_end        | [template_name]  |                                 | {\"question\": \"hello\"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |\n",
            " |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
            " |\n",
            " |      Here are declarations associated with the events shown above:\n",
            " |\n",
            " |      `format_docs`:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          def format_docs(docs: List[Document]) -> str:\n",
            " |              '''Format the docs.'''\n",
            " |              return \", \".join([doc.page_content for doc in docs])\n",
            " |\n",
            " |          format_docs = RunnableLambda(format_docs)\n",
            " |\n",
            " |      `some_tool`:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          @tool\n",
            " |          def some_tool(x: int, y: str) -> dict:\n",
            " |              '''Some_tool.'''\n",
            " |              return {\"x\": x, \"y\": y}\n",
            " |\n",
            " |      `prompt`:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          template = ChatPromptTemplate.from_messages(\n",
            " |              [(\"system\", \"You are Cat Agent 007\"), (\"human\", \"{question}\")]\n",
            " |          ).with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})\n",
            " |\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |\n",
            " |          async def reverse(s: str) -> str:\n",
            " |              return s[::-1]\n",
            " |\n",
            " |          chain = RunnableLambda(func=reverse)\n",
            " |\n",
            " |          events = [\n",
            " |              event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
            " |          ]\n",
            " |\n",
            " |          # will produce the following events (run_id has been omitted for brevity):\n",
            " |          [\n",
            " |              {\n",
            " |                  \"data\": {\"input\": \"hello\"},\n",
            " |                  \"event\": \"on_chain_start\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |              {\n",
            " |                  \"data\": {\"chunk\": \"olleh\"},\n",
            " |                  \"event\": \"on_chain_stream\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |              {\n",
            " |                  \"data\": {\"output\": \"olleh\"},\n",
            " |                  \"event\": \"on_chain_end\",\n",
            " |                  \"metadata\": {},\n",
            " |                  \"name\": \"reverse\",\n",
            " |                  \"tags\": [],\n",
            " |              },\n",
            " |          ]\n",
            " |\n",
            " |      Args:\n",
            " |          input: The input to the runnable.\n",
            " |          config: The config to use for the runnable.\n",
            " |          version: The version of the schema to use either `v2` or `v1`.\n",
            " |                   Users should use `v2`.\n",
            " |                   `v1` is for backwards compatibility and will be deprecated\n",
            " |                   in 0.4.0.\n",
            " |                   No default will be assigned until the API is stabilized.\n",
            " |          include_names: Only include events from runnables with matching names.\n",
            " |          include_types: Only include events from runnables with matching types.\n",
            " |          include_tags: Only include events from runnables with matching tags.\n",
            " |          exclude_names: Exclude events from runnables with matching names.\n",
            " |          exclude_types: Exclude events from runnables with matching types.\n",
            " |          exclude_tags: Exclude events from runnables with matching tags.\n",
            " |          kwargs: Additional keyword arguments to pass to the runnable.\n",
            " |              These will be passed to astream_log as this implementation\n",
            " |              of astream_events is built on top of astream_log.\n",
            " |\n",
            " |      Returns:\n",
            " |          An async stream of StreamEvents.\n",
            " |\n",
            " |      Notes\n",
            " |      -----\n",
            " |      .. beta::\n",
            " |         This API is in beta and may change in the future.\n",
            " |\n",
            " |  async astream_log(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'\n",
            " |      Stream all output from a runnable, as reported to the callback system.\n",
            " |      This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
            " |\n",
            " |      Output is streamed as Log objects, which include a list of\n",
            " |      jsonpatch ops that describe how the state of the run has changed in each\n",
            " |      step, and the final state of the run.\n",
            " |\n",
            " |      The jsonpatch ops can be applied in order to construct state.\n",
            " |\n",
            " |      Args:\n",
            " |          input: The input to the runnable.\n",
            " |          config: The config to use for the runnable.\n",
            " |          diff: Whether to yield diffs between each step, or the current state.\n",
            " |          with_streamed_output_list: Whether to yield the streamed_output list.\n",
            " |          include_names: Only include logs with these names.\n",
            " |          include_types: Only include logs with these types.\n",
            " |          include_tags: Only include logs with these tags.\n",
            " |          exclude_names: Exclude logs with these names.\n",
            " |          exclude_types: Exclude logs with these types.\n",
            " |          exclude_tags: Exclude logs with these tags.\n",
            " |\n",
            " |  async atransform(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
            " |      Default implementation of atransform, which buffers input and calls astream.\n",
            " |      Subclasses should override this method if they can start producing output while\n",
            " |      input is still being generated.\n",
            " |\n",
            " |  batch(self, inputs: 'List[Input]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'List[Output]'\n",
            " |      Default implementation runs invoke in parallel using a thread pool executor.\n",
            " |\n",
            " |      The default implementation of batch works well for IO bound runnables.\n",
            " |\n",
            " |      Subclasses should override this method if they can batch more efficiently;\n",
            " |      e.g., if the underlying runnable uses an API which supports a batch mode.\n",
            " |\n",
            " |  batch_as_completed(self, inputs: 'List[Input]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'Iterator[Tuple[int, Union[Output, Exception]]]'\n",
            " |      Run invoke in parallel on a list of inputs,\n",
            " |      yielding results as they complete.\n",
            " |\n",
            " |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
            " |      Bind arguments to a Runnable, returning a new Runnable.\n",
            " |\n",
            " |      Useful when a runnable in a chain requires an argument that is not\n",
            " |      in the output of the previous runnable or included in the user input.\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_community.chat_models import ChatOllama\n",
            " |          from langchain_core.output_parsers import StrOutputParser\n",
            " |\n",
            " |          llm = ChatOllama(model='llama2')\n",
            " |\n",
            " |          # Without bind.\n",
            " |          chain = (\n",
            " |              llm\n",
            " |              | StrOutputParser()\n",
            " |          )\n",
            " |\n",
            " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
            " |          # Output is 'One two three four five.'\n",
            " |\n",
            " |          # With bind.\n",
            " |          chain = (\n",
            " |              llm.bind(stop=[\"three\"])\n",
            " |              | StrOutputParser()\n",
            " |          )\n",
            " |\n",
            " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
            " |          # Output is 'One two'\n",
            " |\n",
            " |  config_schema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'Type[BaseModel]'\n",
            " |      The type of config this runnable accepts specified as a pydantic model.\n",
            " |\n",
            " |      To mark a field as configurable, see the `configurable_fields`\n",
            " |      and `configurable_alternatives` methods.\n",
            " |\n",
            " |      Args:\n",
            " |          include: A list of fields to include in the config schema.\n",
            " |\n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate config.\n",
            " |\n",
            " |  get_graph(self, config: 'Optional[RunnableConfig]' = None) -> 'Graph'\n",
            " |      Return a graph representation of this runnable.\n",
            " |\n",
            " |  get_input_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
            " |      Get a pydantic model that can be used to validate input to the runnable.\n",
            " |\n",
            " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
            " |      methods will have a dynamic input schema that depends on which\n",
            " |      configuration the runnable is invoked with.\n",
            " |\n",
            " |      This method allows to get an input schema for a specific configuration.\n",
            " |\n",
            " |      Args:\n",
            " |          config: A config to use when generating the schema.\n",
            " |\n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate input.\n",
            " |\n",
            " |  get_name(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -> 'str'\n",
            " |      Get the name of the runnable.\n",
            " |\n",
            " |  get_output_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
            " |      Get a pydantic model that can be used to validate output to the runnable.\n",
            " |\n",
            " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
            " |      methods will have a dynamic output schema that depends on which\n",
            " |      configuration the runnable is invoked with.\n",
            " |\n",
            " |      This method allows to get an output schema for a specific configuration.\n",
            " |\n",
            " |      Args:\n",
            " |          config: A config to use when generating the schema.\n",
            " |\n",
            " |      Returns:\n",
            " |          A pydantic model that can be used to validate output.\n",
            " |\n",
            " |  get_prompts(self, config: 'Optional[RunnableConfig]' = None) -> 'List[BasePromptTemplate]'\n",
            " |\n",
            " |  map(self) -> 'Runnable[List[Input], List[Output]]'\n",
            " |      Return a new Runnable that maps a list of inputs to a list of outputs,\n",
            " |      by calling invoke() with each input.\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |          .. code-block:: python\n",
            " |\n",
            " |                  from langchain_core.runnables import RunnableLambda\n",
            " |\n",
            " |                  def _lambda(x: int) -> int:\n",
            " |                      return x + 1\n",
            " |\n",
            " |                  runnable = RunnableLambda(_lambda)\n",
            " |                  print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]\n",
            " |\n",
            " |  pick(self, keys: 'Union[str, List[str]]') -> 'RunnableSerializable[Any, Any]'\n",
            " |      Pick keys from the dict output of this runnable.\n",
            " |\n",
            " |      Pick single key:\n",
            " |          .. code-block:: python\n",
            " |\n",
            " |              import json\n",
            " |\n",
            " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
            " |\n",
            " |              as_str = RunnableLambda(str)\n",
            " |              as_json = RunnableLambda(json.loads)\n",
            " |              chain = RunnableMap(str=as_str, json=as_json)\n",
            " |\n",
            " |              chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3]}\n",
            " |\n",
            " |              json_only_chain = chain.pick(\"json\")\n",
            " |              json_only_chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> [1, 2, 3]\n",
            " |\n",
            " |      Pick list of keys:\n",
            " |          .. code-block:: python\n",
            " |\n",
            " |              from typing import Any\n",
            " |\n",
            " |              import json\n",
            " |\n",
            " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
            " |\n",
            " |              as_str = RunnableLambda(str)\n",
            " |              as_json = RunnableLambda(json.loads)\n",
            " |              def as_bytes(x: Any) -> bytes:\n",
            " |                  return bytes(x, \"utf-8\")\n",
            " |\n",
            " |              chain = RunnableMap(\n",
            " |                  str=as_str,\n",
            " |                  json=as_json,\n",
            " |                  bytes=RunnableLambda(as_bytes)\n",
            " |              )\n",
            " |\n",
            " |              chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
            " |\n",
            " |              json_and_bytes_chain = chain.pick([\"json\", \"bytes\"])\n",
            " |              json_and_bytes_chain.invoke(\"[1, 2, 3]\")\n",
            " |              # -> {\"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
            " |\n",
            " |  pipe(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -> 'RunnableSerializable[Input, Other]'\n",
            " |      Compose this Runnable with Runnable-like objects to make a RunnableSequence.\n",
            " |\n",
            " |      Equivalent to `RunnableSequence(self, *others)` or `self | others[0] | ...`\n",
            " |\n",
            " |      Example:\n",
            " |          .. code-block:: python\n",
            " |\n",
            " |              from langchain_core.runnables import RunnableLambda\n",
            " |\n",
            " |              def add_one(x: int) -> int:\n",
            " |                  return x + 1\n",
            " |\n",
            " |              def mul_two(x: int) -> int:\n",
            " |                  return x * 2\n",
            " |\n",
            " |              runnable_1 = RunnableLambda(add_one)\n",
            " |              runnable_2 = RunnableLambda(mul_two)\n",
            " |              sequence = runnable_1.pipe(runnable_2)\n",
            " |              # Or equivalently:\n",
            " |              # sequence = runnable_1 | runnable_2\n",
            " |              # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
            " |              sequence.invoke(1)\n",
            " |              await sequence.ainvoke(1)\n",
            " |              # -> 4\n",
            " |\n",
            " |              sequence.batch([1, 2, 3])\n",
            " |              await sequence.abatch([1, 2, 3])\n",
            " |              # -> [4, 6, 8]\n",
            " |\n",
            " |  stream(self, input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
            " |      Default implementation of stream, which calls invoke.\n",
            " |      Subclasses should override this method if they support streaming output.\n",
            " |\n",
            " |  transform(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
            " |      Default implementation of transform, which buffers input and then calls stream.\n",
            " |      Subclasses should override this method if they can start producing output while\n",
            " |      input is still being generated.\n",
            " |\n",
            " |  with_config(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
            " |      Bind config to a Runnable, returning a new Runnable.\n",
            " |\n",
            " |  with_fallbacks(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,), exception_key: 'Optional[str]' = None) -> 'RunnableWithFallbacksT[Input, Output]'\n",
            " |      Add fallbacks to a runnable, returning a new Runnable.\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |          .. code-block:: python\n",
            " |\n",
            " |              from typing import Iterator\n",
            " |\n",
            " |              from langchain_core.runnables import RunnableGenerator\n",
            " |\n",
            " |\n",
            " |              def _generate_immediate_error(input: Iterator) -> Iterator[str]:\n",
            " |                  raise ValueError()\n",
            " |                  yield \"\"\n",
            " |\n",
            " |\n",
            " |              def _generate(input: Iterator) -> Iterator[str]:\n",
            " |                  yield from \"foo bar\"\n",
            " |\n",
            " |\n",
            " |              runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(\n",
            " |                  [RunnableGenerator(_generate)]\n",
            " |                  )\n",
            " |              print(''.join(runnable.stream({}))) #foo bar\n",
            " |\n",
            " |      Args:\n",
            " |          fallbacks: A sequence of runnables to try if the original runnable fails.\n",
            " |          exceptions_to_handle: A tuple of exception types to handle.\n",
            " |          exception_key: If string is specified then handled exceptions will be passed\n",
            " |              to fallbacks as part of the input under the specified key. If None,\n",
            " |              exceptions will not be passed to fallbacks. If used, the base runnable\n",
            " |              and its fallbacks must accept a dictionary as input.\n",
            " |\n",
            " |      Returns:\n",
            " |          A new Runnable that will try the original runnable, and then each\n",
            " |          fallback in order, upon failures.\n",
            " |\n",
            " |  with_listeners(self, *, on_start: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_end: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_error: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None) -> 'Runnable[Input, Output]'\n",
            " |      Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
            " |\n",
            " |      on_start: Called before the runnable starts running, with the Run object.\n",
            " |      on_end: Called after the runnable finishes running, with the Run object.\n",
            " |      on_error: Called if the runnable throws an error, with the Run object.\n",
            " |\n",
            " |      The Run object contains information about the run, including its id,\n",
            " |      type, input, output, error, start_time, end_time, and any tags or metadata\n",
            " |      added to the run.\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |          from langchain_core.tracers.schemas import Run\n",
            " |\n",
            " |          import time\n",
            " |\n",
            " |          def test_runnable(time_to_sleep : int):\n",
            " |              time.sleep(time_to_sleep)\n",
            " |\n",
            " |          def fn_start(run_obj: Run):\n",
            " |              print(\"start_time:\", run_obj.start_time)\n",
            " |\n",
            " |          def fn_end(run_obj: Run):\n",
            " |              print(\"end_time:\", run_obj.end_time)\n",
            " |\n",
            " |          chain = RunnableLambda(test_runnable).with_listeners(\n",
            " |              on_start=fn_start,\n",
            " |              on_end=fn_end\n",
            " |          )\n",
            " |          chain.invoke(2)\n",
            " |\n",
            " |  with_retry(self, *, retry_if_exception_type: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,), wait_exponential_jitter: 'bool' = True, stop_after_attempt: 'int' = 3) -> 'Runnable[Input, Output]'\n",
            " |      Create a new Runnable that retries the original runnable on exceptions.\n",
            " |\n",
            " |      Example:\n",
            " |\n",
            " |      .. code-block:: python\n",
            " |\n",
            " |          from langchain_core.runnables import RunnableLambda\n",
            " |\n",
            " |          count = 0\n",
            " |\n",
            " |\n",
            " |          def _lambda(x: int) -> None:\n",
            " |              global count\n",
            " |              count = count + 1\n",
            " |              if x == 1:\n",
            " |                  raise ValueError(\"x is 1\")\n",
            " |              else:\n",
            " |                   pass\n",
            " |\n",
            " |\n",
            " |          runnable = RunnableLambda(_lambda)\n",
            " |          try:\n",
            " |              runnable.with_retry(\n",
            " |                  stop_after_attempt=2,\n",
            " |                  retry_if_exception_type=(ValueError,),\n",
            " |              ).invoke(1)\n",
            " |          except ValueError:\n",
            " |              pass\n",
            " |\n",
            " |          assert (count == 2)\n",
            " |\n",
            " |\n",
            " |      Args:\n",
            " |          retry_if_exception_type: A tuple of exception types to retry on\n",
            " |          wait_exponential_jitter: Whether to add jitter to the wait time\n",
            " |                                   between retries\n",
            " |          stop_after_attempt: The maximum number of attempts to make before giving up\n",
            " |\n",
            " |      Returns:\n",
            " |          A new Runnable that retries the original runnable on exceptions.\n",
            " |\n",
            " |  with_types(self, *, input_type: 'Optional[Type[Input]]' = None, output_type: 'Optional[Type[Output]]' = None) -> 'Runnable[Input, Output]'\n",
            " |      Bind input and output types to a Runnable, returning a new Runnable.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from langchain_core.runnables.base.Runnable:\n",
            " |\n",
            " |  InputType\n",
            " |      The type of input this runnable accepts specified as a type annotation.\n",
            " |\n",
            " |  OutputType\n",
            " |      The type of output this runnable produces specified as a type annotation.\n",
            " |\n",
            " |  config_specs\n",
            " |      List configurable fields for this runnable.\n",
            " |\n",
            " |  input_schema\n",
            " |      The type of input this runnable accepts specified as a pydantic model.\n",
            " |\n",
            " |  output_schema\n",
            " |      The type of output this runnable produces specified as a pydantic model.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from langchain_core.runnables.base.Runnable:\n",
            " |\n",
            " |  name = None\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from typing.Generic:\n",
            " |\n",
            " |  __class_getitem__(...) from pydantic.v1.main.ModelMetaclass\n",
            " |      Parameterizes a generic class.\n",
            " |\n",
            " |      At least, parameterizing a generic class is the *main* thing this\n",
            " |      method does. For example, for some generic class `Foo`, this is called\n",
            " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
            " |\n",
            " |      However, note that this method is also called when defining generic\n",
            " |      classes in the first place with `class Foo[T]: ...`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(BM25Retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def process_file(file_path, embeddings):\n",
        "#     if os.path.isfile(file_path):\n",
        "        # with open(file_path, \"rb\") as f:\n",
        "        #     reader = PdfReader(f)\n",
        "        #     text = \"\"\n",
        "        #     for page in reader.pages:\n",
        "        #         text += page.extract_text()\n",
        "        #     with open(\"temp_text.txt\", \"w\") as text_file:\n",
        "        #         text_file.write(text)\n",
        "            # loader = TextLoader(\"temp_text.txt\")\n",
        "            # data = loader.load()\n",
        "            # text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
        "            # chunks = text_splitter.split_documents(data)\n",
        "            # if chunks:\n",
        "            #     embeddings_list = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
        "            #     if embeddings_list:\n",
        "            #         vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
        "            #         return vectorstore\n",
        "    # return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resume_processed = process_file(resume_file, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.retrievers import BM25Retriever\n",
        "BM25Retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to analyze inputs and return relevant information\n",
        "def analyze_inputs(job_file_path, resume_file_path, job_ad_text, resume_text):\n",
        "    if job_file_path and resume_file_path:\n",
        "        # Use the local Mistral model\n",
        "        # embeddings = CustomEmbeddings(model_name=BASE_MODEL)\n",
        "        \n",
        "        from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name='/home/james/models/BAAI/bge-base-en-v1.5',\n",
        "            model_kwargs={\"device\": \"cuda\"},\n",
        "            encode_kwargs={\"normalize_embeddings\": True},\n",
        "        )\n",
        "\n",
        "        job_ad_vectorstore = process_file(job_file_path, embeddings)\n",
        "        resume_vectorstore = process_file(resume_file_path, embeddings)\n",
        "\n",
        "        if job_ad_vectorstore and resume_vectorstore:\n",
        "            # retriever = BM25Retriever(vector_db=job_ad_vectorstore.as_retriever())\n",
        "            chain = (\n",
        "                {\"context\": retriever, \"question\": passthrough}\n",
        "                | PROMPT\n",
        "                | ChatOllama()\n",
        "                | passthrough  # Simple output parsing\n",
        "            )\n",
        "            response = chain.invoke(\"Analyze the resume based on the job description\")\n",
        "            return response\n",
        "\n",
        "    return \"Failed to pro\n",
        "\n",
        "cess the files.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/home/james/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'us-api.i.posthog.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for BM25Retriever\ndocs\n  field required (type=value_error.missing)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m analyze_inputs(job_file, resume_file, job_ad_text, resume_text)\n",
            "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36manalyze_inputs\u001b[0;34m(job_file_path, resume_file_path, job_ad_text, resume_text)\u001b[0m\n\u001b[1;32m     16\u001b[0m resume_vectorstore \u001b[38;5;241m=\u001b[39m process_file(resume_file_path, embeddings)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_ad_vectorstore \u001b[38;5;129;01mand\u001b[39;00m resume_vectorstore:\n\u001b[0;32m---> 19\u001b[0m     retriever \u001b[38;5;241m=\u001b[39m BM25Retriever(vector_db\u001b[38;5;241m=\u001b[39mjob_ad_vectorstore\u001b[38;5;241m.\u001b[39mas_retriever())\n\u001b[1;32m     20\u001b[0m     chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     21\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: passthrough}\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;241m|\u001b[39m PROMPT\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;241m|\u001b[39m ChatOllama()\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;241m|\u001b[39m passthrough  \u001b[38;5;66;03m# Simple output parsing\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyze the resume based on the job description\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for BM25Retriever\ndocs\n  field required (type=value_error.missing)"
          ]
        }
      ],
      "source": [
        "analyze_inputs(job_file, resume_file, job_ad_text, resume_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.retrievers.bm25.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IsDnlE9RLOVI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# result = analyze_inputs(uploaded_files, job_ad_text, resume_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fiz2mRy_LTvh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-28 16:28:37.762 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run C:\\Users\\teres\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
            "2024-06-28 16:28:37.764 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ],
      "source": [
        "# https://stackoverflow.com/questions/45480280/convert-scanned-pdf-to-text-python\n",
        "# https://github.com/stanfordnlp/dspy/issues/835\n",
        "# https://dspy-docs.vercel.app/docs/deep-dive/retrieval_models_clients/ChromadbRM\n",
        "# https://stackoverflow.com/questions/77925185/valueerror-expected-embeddingfunction-call-to-have-the-following-signature\n",
        "# https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Advanced%20Retrieval%20With%20LangChain.ipynb\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
