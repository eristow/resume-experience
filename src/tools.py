"""
tools.py

This module provides various utility functions and tools for processing job descriptions and resumes. More specifically, it includes functions for analyzing the inputs, extracting text from files, and generating chat responses based on the analysis.
"""

import os
import traceback
import docx
import pdf2image
import pytesseract
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from pytesseract import Output
from langchain_community.chat_models import ChatOllama
from custom_embeddings import CustomEmbeddings
from prompts import (
    ANALYSIS_QUESTION,
    ANALYSIS_PROMPT,
    CHAT_QUESTION,
    CHAT_PROMPT,
    passthrough,
)

OCR_LANG = "eng"


def analyze_inputs(job_file_path, resume_file_path):
    """
    Analyzes the inputs by processing the job file and resume file using the Mistral model.

    Args:
        job_file_path (str): The file path of the job description file.
        resume_file_path (str): The file path of the resume file.

    Returns:
        str: The response generated by the Mistral model based on the analysis of the resume and job description.
            If the analysis fails, it returns "Failed to process the files."
        job_ad_retriever: The job ad retriever object.
        resume_retriever: The resume retriever object.
    """
    job_ad_vectorstore = None
    resume_vectorstore = None
    job_ad_retriever = None
    resume_retriever = None

    if job_file_path and resume_file_path:
        # Use the local Mistral model
        embeddings = CustomEmbeddings(model_name="./models/mistral")

        job_ad_vectorstore = process_file(job_file_path, embeddings)
        resume_vectorstore = process_file(resume_file_path, embeddings)
        print(f"job_ad_vectorstore: {job_ad_vectorstore}")
        print(f"resume_vectorstore: {resume_vectorstore}")

        if job_ad_vectorstore and resume_vectorstore:
            print("Both vectorstores exist")
            job_ad_retriever = job_ad_vectorstore.as_retriever()
            resume_retriever = resume_vectorstore.as_retriever()
            print("After creating retrievers")
            chain = (
                {
                    "resume_context": resume_retriever,
                    "job_ad_context": job_ad_retriever,
                    "question": lambda x: ANALYSIS_QUESTION,
                }
                | ANALYSIS_PROMPT
                | ChatOllama(model="mistral:v0.3", temperature=0.3)
                | passthrough  # Simple output parsing
            )
            print("After creating chain")
            response = chain.invoke("Analyze the resume based on the job description")
            print("After invoking chain to generate response")
            return response, job_ad_retriever, resume_retriever

    return "Failed to process the files."


def extract_text_from_file(uploaded_file, file_path):
    """
    Extracts text from a given file.

    Args:
        uploaded_file (File): The uploaded file object.
        file_path (str): The path to the uploaded file.

    Returns:
        str: The extracted text from the file, or None if no text is found.
    """
    file_extension = uploaded_file.name.split(".")[-1].lower()
    text = ""

    if file_extension == "pdf":
        text = extract_text_from_image(file_path)
    # TODO: test this branch with a doc/docx file
    elif file_extension in ["doc", "docx"]:
        doc = docx.Document(uploaded_file)
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"

    return None if not text else text


# Doesn't work if using uploaded_file. Only with file_path
def extract_text_from_image(file_path):
    """
    Extracts text from a PDF image using OCR (Optical Character Recognition).

    Args:
        file_path (str): The path to the PDF file.

    Returns:
        str: The extracted text from the PDF image.
    """

    text = ""
    images = pdf2image.convert_from_path(file_path)

    for image in images:
        ocr_dict = pytesseract.image_to_data(
            image, lang=OCR_LANG, output_type=Output.DICT
        )
        text += " ".join([word for word in ocr_dict["text"] if word])

    return text


def process_file(file_path, embeddings):
    """
    Process a file by extracting text, splitting it into chunks, and creating a vectorstore.

    Args:
        file_path (str): The path to the file to be processed.
        embeddings: The embeddings object used for creating the vectorstore.

    Returns:
        vectorstore: The created vectorstore object.

    Raises:
        Exception: If an error occurs while creating the vectorstore.
    """
    if os.path.isfile(file_path):
        with open(file_path, "rb") as f:
            text = extract_text_from_file(f, file_path)
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=7500, chunk_overlap=100
            )
            print(f"text_splitter: {text_splitter}")
            chunks = text_splitter.split_text(text)
            # print(f"chunks: {chunks}")
            if chunks:
                embeddings_list = embeddings.embed_documents(chunks)
                # print(f"embeddings_list: {embeddings_list}")

                if embeddings_list:
                    print(f"embeddings: {embeddings}")
                    try:
                        vectorstore = Chroma.from_texts(
                            texts=chunks, embedding=embeddings
                        )
                        print(f"vectorstore: {vectorstore}")
                        return vectorstore
                    except Exception as e:
                        print("An error occurred while creating the vectorstore:")
                        traceback.print_exception(type(e), e, e.__traceback__)
                        return None
    return None


def get_chat_response(user_input, job_ad_retriever, resume_retriever):
    """
    Retrieves a chat response based on the user input, resume retriever, and job ad retriever.

    Args:
        user_input (str): The user's input.
        resume_retriever: The resume retriever object.
        job_ad_retriever: The job ad retriever object.

    Returns:
        str: The chat response.
    """
    # Rest of the code...
    print(f"user_input: {user_input}")
    print(f"resume_retriever: {resume_retriever}")
    print(f"job_ad_retriever: {job_ad_retriever}")
    chain = (
        {
            "resume_context": resume_retriever,
            "job_ad_context": job_ad_retriever,
            "user_input": lambda x: user_input,
            "question": lambda x: CHAT_QUESTION,
        }
        | CHAT_PROMPT
        | ChatOllama(model="mistral:v0.3", temperature=0.3)
        | passthrough  # Simple output parsing
    )

    response = chain.invoke(user_input)
    # print(f"chat response: {response}")
    return response
